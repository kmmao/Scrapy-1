[scrapyd]
eggs_dir    = eggs
logs_dir    = logs
items_dir   =
jobs_to_keep = 5
dbs_dir     = dbs
max_proc    = 0
max_proc_per_cpu = 4
finished_to_keep = 100
poll_interval = 5.0
bind_address = 0.0.0.0
http_port   = 6800
debug       = off
runner      = scrapyd.runner
application = scrapyd.app.application
launcher    = scrapyd.launcher.Launcher
webroot     = scrapyd.website.Root

[services]
# 启动项目
schedule.json     = scrapyd.webservice.Schedule
# 0.15版本的新功能。取消蜘蛛游戏（又名作业）。如果作业处于待处理状态，则会将其删除。如果作业正在运行，它将被终止。
cancel.json   = scrapyd.webservice.Cancel
# 将项目添加到项目中，如果项目不存在则创建项目。
addversion.json   = scrapyd.webservice.AddVersion
# 获取上传到此Scrapy服务器的项目列表。
listprojects.json = scrapyd.webservice.ListProjects
# 获取某些项目可用的版本列表。版本按顺序返回，最后一个版本是当前使用的版本。
listversions.json = scrapyd.webservice.ListVersions
# 获取某个项目的最后一个（除非被覆盖）版本中可用的蜘蛛列表。
listspiders.json  = scrapyd.webservice.ListSpiders
# 删除项目及其所有上载的版本。
delproject.json   = scrapyd.webservice.DeleteProject
# 删除项目版本。如果给定项目没有更多可用版本，则该项目也将被删除。
delversion.json   = scrapyd.webservice.DeleteVersion
# 0.15版本的新功能。获取某个项目的待处理，正在运行和已完成的作业列表。
listjobs.json     = scrapyd.webservice.ListJobs
# 检查服务的负载状态。
daemonstatus.json = scrapyd.webservice.DaemonStatus

#[deploy:Wenkuxiazai]
#部署名(部署名可以自行定义)
#url = http://127.0.0.1:6800/
#project = Wenkuxiazai(创建爬虫项目时使用的名称)